{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Clone repo"
      ],
      "metadata": {
        "id": "fG4WSikbrLCr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mx4jFHcSpaga"
      },
      "outputs": [],
      "source": [
        "# Clone GFPGAN and enter the GFPGAN folder\n",
        "%cd /content\n",
        "!rm -rf GFPGAN\n",
        "!git clone https://github.com/TencentARC/GFPGAN.git\n",
        "%cd GFPGAN"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install packages"
      ],
      "metadata": {
        "id": "Mzy1EvzorNBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up the environment\n",
        "# Install basicsr - https://github.com/xinntao/BasicSR\n",
        "# We use BasicSR for both training and inference\n",
        "!pip install basicsr\n",
        "\n",
        "# Install facexlib - https://github.com/xinntao/facexlib\n",
        "# We use face detection and face restoration helper in the facexlib package\n",
        "!pip install facexlib\n",
        "\n",
        "# Install other depencencies\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "!python setup.py develop\n",
        "\n",
        "!pip install realesrgan  # used for enhancing the background (non-face) regions"
      ],
      "metadata": {
        "id": "pLCo0fXdpjRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download pre-trained weight"
      ],
      "metadata": {
        "id": "lzzzqpZJprvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Links to trained weight files\n",
        "\n",
        "v1 - https://github.com/TencentARC/GFPGAN/releases/download/v0.1.0/GFPGANv1.pth\n",
        "v1.2 - https://github.com/TencentARC/GFPGAN/releases/download/v0.2.0/GFPGANCleanv1-NoCE-C2.pth\n",
        "v1.3 - https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.3.pth\n",
        "v1.4 - https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "VeEWYvKupqVb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download weight file\n",
        "!wget https://github.com/TencentARC/GFPGAN/releases/download/v1.3.0/GFPGANv1.4.pth -P experiments/pretrained_models"
      ],
      "metadata": {
        "id": "1InCy-ZUqACE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run model prediction"
      ],
      "metadata": {
        "id": "AMd8vsxCq5C0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_images_dir = \"/content/test_images\" # folder containing images\n",
        "outputs_dir = \"/content/infer_outputs\"   # output files will be saved in this folder\n",
        "upscale = 4\n",
        "version = 1.4"
      ],
      "metadata": {
        "id": "veh8GQyWqD_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf results\n",
        "!python inference_gfpgan.py \\\n",
        "--input {test_images_dir} \\\n",
        "--output {outputs_dir} \\\n",
        "--version {version} \\\n",
        "--upscale {upscale} \\\n",
        "--bg_upsampler realesrgan"
      ],
      "metadata": {
        "id": "ADSspBk9qokm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we use the GFPGAN to restore the above low-quality images\n",
        "# We use [Real-ESRGAN](https://github.com/xinntao/Real-ESRGAN) for enhancing the background (non-face) regions\n",
        "# You can find the different models in https://github.com/TencentARC/GFPGAN#european_castle-model-zoo\n",
        "\n",
        "# Usage: python inference_gfpgan.py -i inputs/whole_imgs -o results -v 1.3 -s 2 [options]...\n",
        "# \n",
        "#  -h                   show this help\n",
        "#  -i input             Input image or folder. Default: inputs/whole_imgs\n",
        "#  -o output            Output folder. Default: results\n",
        "#  -v version           GFPGAN model version. Option: 1 | 1.2 | 1.3. Default: 1.3\n",
        "#  -s upscale           The final upsampling scale of the image. Default: 2\n",
        "#  -bg_upsampler        background upsampler. Default: realesrgan\n",
        "#  -bg_tile             Tile size for background sampler, 0 for no tile during testing. Default: 400\n",
        "#  -suffix              Suffix of the restored faces\n",
        "#  -only_center_face    Only restore the center face\n",
        "#  -aligned             Input are aligned faces\n",
        "#  -ext                 Image extension. Options: auto | jpg | png, auto means using the same extension as inputs. Default: auto"
      ],
      "metadata": {
        "id": "ohiO3y1dqD9Z"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
